{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from vqvaes.vq import VQ\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VQ(\n",
       "  (codebook): Embedding(4, 12)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vq = VQ(\n",
    "    codebook_size=4,\n",
    "    codebook_dim=12\n",
    ")\n",
    "\n",
    "vq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quantized': tensor([[[[ 0.0660, -1.2311, -0.7915, -0.6858, -0.4377, -0.7634,  1.1600,\n",
       "            -0.5719, -1.2919, -0.7813,  0.0328,  0.1664],\n",
       "           [ 0.0660, -1.2311, -0.7915, -0.6858, -0.4377, -0.7634,  1.1600,\n",
       "            -0.5719, -1.2919, -0.7813,  0.0328,  0.1664]],\n",
       " \n",
       "          [[ 0.8181,  0.5823,  1.0346, -0.0613,  1.5635,  1.0844, -0.4846,\n",
       "            -0.3286,  1.2524,  0.5251,  0.2822, -0.2040],\n",
       "           [-0.4393, -0.0342,  1.4439, -0.0670, -1.8643, -0.7695,  0.5740,\n",
       "            -0.7604,  1.3218, -2.2603, -0.0298, -1.3140]]]],\n",
       "        grad_fn=<ViewBackward0>)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = torch.randn((1,  2, 2, 12))\n",
    "vq(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2]), torch.Size([2, 2]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2]])\n",
    "b = torch.tensor([[3, 4],\n",
    "                  [5, 6]])\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2, -2],\n",
       "        [-4, -4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a - b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqvaes-Y5Ctg_tt-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
