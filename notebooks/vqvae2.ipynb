{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "from vqvaes.models.vqvae2 import Encoder, Decoder, VQVAE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(3, 64, 2, 32, 4)\n",
    "inputs = torch.randn(1, 3, 64, 64)\n",
    "z = encoder(inputs)\n",
    "assert z.shape == torch.Size((1, 64, 16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(3, 64, 2, 32, 2)\n",
    "z = encoder(inputs)\n",
    "assert z.shape == torch.Size((1, 64, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(64, 3, 2, 32, 4)\n",
    "inputs = torch.randn(1, 64, 16, 16)\n",
    "x = decoder(inputs)\n",
    "assert x.shape == torch.Size([1, 3, 64, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(64, 3, 2, 32, 2)\n",
    "inputs = torch.randn(1, 64, 32, 32)\n",
    "x = decoder(inputs)\n",
    "assert x.shape == torch.Size([1, 3, 64, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 64, 64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqvae = VQVAE2(\n",
    "    in_channels=3,\n",
    "    num_channels=16,\n",
    "    num_residual_blocks=2,\n",
    "    num_residual_channels=32,\n",
    "    codebook_size=512,\n",
    "    codebook_dim=64,\n",
    "    commitment_cost=0.25,\n",
    "    decay=0.99\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.0062, -0.0441,  0.0010,  ...,  0.0084, -0.0106, -0.0273],\n",
       "           [-0.0637, -0.0636, -0.1000,  ..., -0.0399, -0.0479,  0.0045],\n",
       "           [ 0.0402,  0.0203,  0.0060,  ...,  0.0080,  0.0314, -0.0173],\n",
       "           ...,\n",
       "           [-0.0783, -0.0275, -0.1123,  ..., -0.0211, -0.0659, -0.0153],\n",
       "           [ 0.0210, -0.0157,  0.0239,  ..., -0.0160,  0.0948,  0.0314],\n",
       "           [-0.0323,  0.0043, -0.0249,  ...,  0.0212, -0.0182,  0.0158]],\n",
       " \n",
       "          [[ 0.0062, -0.0180,  0.0065,  ..., -0.0311, -0.0055, -0.0299],\n",
       "           [-0.0307,  0.0719, -0.0515,  ...,  0.0457, -0.0329, -0.0184],\n",
       "           [ 0.0008,  0.0168, -0.0062,  ..., -0.0228, -0.0295, -0.0490],\n",
       "           ...,\n",
       "           [-0.0257,  0.0450, -0.0125,  ..., -0.0095,  0.0078, -0.0067],\n",
       "           [ 0.0012,  0.0020, -0.0146,  ..., -0.0662,  0.0048, -0.0524],\n",
       "           [-0.0702, -0.0308, -0.0109,  ..., -0.0092, -0.0214, -0.0067]],\n",
       " \n",
       "          [[ 0.1279,  0.0957,  0.1260,  ...,  0.0901,  0.1621,  0.1154],\n",
       "           [ 0.1023,  0.1806,  0.0801,  ...,  0.1214,  0.1158,  0.1046],\n",
       "           [ 0.1338,  0.2023,  0.1622,  ...,  0.1661,  0.1099,  0.1359],\n",
       "           ...,\n",
       "           [ 0.1117,  0.1797,  0.1079,  ...,  0.1383,  0.1365,  0.1500],\n",
       "           [ 0.1326,  0.2341,  0.1218,  ...,  0.2146,  0.1174,  0.1233],\n",
       "           [ 0.1076,  0.1102,  0.1492,  ...,  0.1107,  0.1449,  0.1281]]]],\n",
       "        grad_fn=<ConvolutionBackward0>),\n",
       " {'quantize': tensor([[[[ 1.6585e-05,  1.6587e-05,  1.6585e-05,  ..., -1.2106e-03,\n",
       "              1.6587e-05, -1.6215e-04],\n",
       "            [ 1.6587e-05, -1.1708e-03,  1.6585e-05,  ..., -1.6215e-04,\n",
       "             -1.1708e-03,  1.6585e-05],\n",
       "            [ 1.6585e-05,  1.6585e-05, -1.1708e-03,  ..., -1.6215e-04,\n",
       "              1.6585e-05,  1.6585e-05],\n",
       "            ...,\n",
       "            [ 1.6587e-05, -1.2106e-03,  1.6585e-05,  ..., -1.2106e-03,\n",
       "             -1.2106e-03,  1.6585e-05],\n",
       "            [ 1.6585e-05,  1.6585e-05,  1.6585e-05,  ..., -1.6215e-04,\n",
       "             -1.6215e-04,  1.6585e-05],\n",
       "            [ 1.6585e-05, -1.1708e-03,  1.9035e-04,  ...,  1.9035e-04,\n",
       "             -1.1708e-03, -1.1708e-03]],\n",
       "  \n",
       "           [[ 8.6910e-04,  8.6910e-04,  8.6910e-04,  ..., -9.5763e-05,\n",
       "              8.6910e-04,  1.1796e-03],\n",
       "            [ 8.6910e-04,  1.5276e-04,  8.6910e-04,  ...,  1.1796e-03,\n",
       "              1.5276e-04,  8.6910e-04],\n",
       "            [ 8.6910e-04,  8.6910e-04,  1.5276e-04,  ...,  1.1796e-03,\n",
       "              8.6910e-04,  8.6910e-04],\n",
       "            ...,\n",
       "            [ 8.6910e-04, -9.5763e-05,  8.6910e-04,  ..., -9.5763e-05,\n",
       "             -9.5763e-05,  8.6910e-04],\n",
       "            [ 8.6910e-04,  8.6910e-04,  8.6910e-04,  ...,  1.1796e-03,\n",
       "              1.1796e-03,  8.6910e-04],\n",
       "            [ 8.6910e-04,  1.5276e-04,  7.3452e-04,  ...,  7.3452e-04,\n",
       "              1.5276e-04,  1.5276e-04]],\n",
       "  \n",
       "           [[-1.6543e-03, -1.6543e-03, -1.6543e-03,  ..., -3.2474e-04,\n",
       "             -1.6543e-03,  1.4962e-03],\n",
       "            [-1.6543e-03,  3.3383e-04, -1.6543e-03,  ...,  1.4962e-03,\n",
       "              3.3383e-04, -1.6543e-03],\n",
       "            [-1.6543e-03, -1.6543e-03,  3.3384e-04,  ...,  1.4962e-03,\n",
       "             -1.6543e-03, -1.6543e-03],\n",
       "            ...,\n",
       "            [-1.6543e-03, -3.2474e-04, -1.6543e-03,  ..., -3.2474e-04,\n",
       "             -3.2474e-04, -1.6543e-03],\n",
       "            [-1.6543e-03, -1.6543e-03, -1.6543e-03,  ...,  1.4962e-03,\n",
       "              1.4962e-03, -1.6543e-03],\n",
       "            [-1.6543e-03,  3.3383e-04, -7.7078e-04,  ..., -7.7078e-04,\n",
       "              3.3383e-04,  3.3383e-04]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[-1.3292e-04, -1.3292e-04, -1.3292e-04,  ..., -3.3267e-04,\n",
       "             -1.3292e-04, -1.2335e-03],\n",
       "            [-1.3292e-04, -4.9892e-04, -1.3292e-04,  ..., -1.2335e-03,\n",
       "             -4.9892e-04, -1.3292e-04],\n",
       "            [-1.3292e-04, -1.3292e-04, -4.9892e-04,  ..., -1.2335e-03,\n",
       "             -1.3292e-04, -1.3292e-04],\n",
       "            ...,\n",
       "            [-1.3292e-04, -3.3267e-04, -1.3292e-04,  ..., -3.3267e-04,\n",
       "             -3.3267e-04, -1.3292e-04],\n",
       "            [-1.3292e-04, -1.3292e-04, -1.3292e-04,  ..., -1.2335e-03,\n",
       "             -1.2335e-03, -1.3292e-04],\n",
       "            [-1.3292e-04, -4.9892e-04, -1.1298e-03,  ..., -1.1298e-03,\n",
       "             -4.9891e-04, -4.9891e-04]],\n",
       "  \n",
       "           [[-2.6646e-04, -2.6646e-04, -2.6646e-04,  ...,  1.0241e-03,\n",
       "             -2.6646e-04,  1.5253e-04],\n",
       "            [-2.6646e-04, -1.8597e-03, -2.6646e-04,  ...,  1.5253e-04,\n",
       "             -1.8597e-03, -2.6646e-04],\n",
       "            [-2.6646e-04, -2.6646e-04, -1.8597e-03,  ...,  1.5253e-04,\n",
       "             -2.6646e-04, -2.6646e-04],\n",
       "            ...,\n",
       "            [-2.6646e-04,  1.0241e-03, -2.6646e-04,  ...,  1.0241e-03,\n",
       "              1.0241e-03, -2.6646e-04],\n",
       "            [-2.6646e-04, -2.6646e-04, -2.6646e-04,  ...,  1.5253e-04,\n",
       "              1.5253e-04, -2.6646e-04],\n",
       "            [-2.6646e-04, -1.8597e-03, -1.6922e-03,  ..., -1.6922e-03,\n",
       "             -1.8597e-03, -1.8597e-03]],\n",
       "  \n",
       "           [[-5.4497e-04, -5.4497e-04, -5.4497e-04,  ..., -1.1876e-03,\n",
       "             -5.4497e-04,  7.7601e-04],\n",
       "            [-5.4497e-04, -1.3994e-04, -5.4497e-04,  ...,  7.7601e-04,\n",
       "             -1.3993e-04, -5.4497e-04],\n",
       "            [-5.4497e-04, -5.4497e-04, -1.3994e-04,  ...,  7.7601e-04,\n",
       "             -5.4497e-04, -5.4497e-04],\n",
       "            ...,\n",
       "            [-5.4497e-04, -1.1876e-03, -5.4497e-04,  ..., -1.1876e-03,\n",
       "             -1.1876e-03, -5.4497e-04],\n",
       "            [-5.4497e-04, -5.4497e-04, -5.4497e-04,  ...,  7.7601e-04,\n",
       "              7.7601e-04, -5.4497e-04],\n",
       "            [-5.4497e-04, -1.3994e-04, -9.4522e-04,  ..., -9.4522e-04,\n",
       "             -1.3994e-04, -1.3994e-04]]]], grad_fn=<PermuteBackward0>),\n",
       "  'loss': tensor(0.0014, grad_fn=<MulBackward0>),\n",
       "  'perplexity': tensor(5.0243)},\n",
       " {'quantize': tensor([[[[-0.0018, -0.0018, -0.0018,  ..., -0.0018, -0.0018, -0.0018],\n",
       "            [-0.0018, -0.0018, -0.0018,  ..., -0.0018, -0.0018, -0.0018],\n",
       "            [-0.0018, -0.0018, -0.0018,  ..., -0.0018, -0.0018, -0.0018],\n",
       "            ...,\n",
       "            [-0.0018, -0.0018, -0.0018,  ..., -0.0018, -0.0018, -0.0018],\n",
       "            [-0.0018, -0.0018, -0.0018,  ..., -0.0018, -0.0018, -0.0018],\n",
       "            [-0.0018, -0.0018, -0.0018,  ..., -0.0018, -0.0018, -0.0018]],\n",
       "  \n",
       "           [[ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
       "            [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
       "            [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
       "            ...,\n",
       "            [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
       "            [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
       "            [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002]],\n",
       "  \n",
       "           [[ 0.0009,  0.0009,  0.0009,  ...,  0.0009,  0.0009,  0.0009],\n",
       "            [ 0.0009,  0.0009,  0.0009,  ...,  0.0009,  0.0009,  0.0009],\n",
       "            [ 0.0009,  0.0009,  0.0009,  ...,  0.0009,  0.0009,  0.0009],\n",
       "            ...,\n",
       "            [ 0.0009,  0.0009,  0.0009,  ...,  0.0009,  0.0009,  0.0009],\n",
       "            [ 0.0009,  0.0009,  0.0009,  ...,  0.0009,  0.0009,  0.0009],\n",
       "            [ 0.0009,  0.0009,  0.0009,  ...,  0.0009,  0.0009,  0.0009]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0019,  0.0019,  0.0019,  ...,  0.0019,  0.0019,  0.0019],\n",
       "            [ 0.0019,  0.0019,  0.0019,  ...,  0.0019,  0.0019,  0.0019],\n",
       "            [ 0.0019,  0.0019,  0.0019,  ...,  0.0019,  0.0019,  0.0019],\n",
       "            ...,\n",
       "            [ 0.0019,  0.0019,  0.0019,  ...,  0.0019,  0.0019,  0.0019],\n",
       "            [ 0.0019,  0.0019,  0.0019,  ...,  0.0019,  0.0019,  0.0019],\n",
       "            [ 0.0019,  0.0019,  0.0019,  ...,  0.0019,  0.0019,  0.0019]],\n",
       "  \n",
       "           [[-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
       "            [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
       "            [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
       "            ...,\n",
       "            [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
       "            [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
       "            [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005]],\n",
       "  \n",
       "           [[ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
       "            [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
       "            [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
       "            ...,\n",
       "            [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
       "            [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
       "            [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005]]]],\n",
       "         grad_fn=<PermuteBackward0>),\n",
       "  'loss': tensor(0.0088, grad_fn=<MulBackward0>),\n",
       "  'perplexity': tensor(1.0658)})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 128, 128)\n",
    "vqvae(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqvaes-Y5Ctg_tt-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
